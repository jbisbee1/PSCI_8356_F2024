<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture 7</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Bisbee" />
    <script src="libs/header-attrs-2.16/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/lexis.css" type="text/css" />
    <link rel="stylesheet" href="css/lexis-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Lecture 7
]
.subtitle[
## Quantitative Political Science
]
.author[
### Prof. Bisbee
]
.institute[
### Vanderbilt University
]
.date[
### Lecture Date: 2023/09/21
Slides Updated: 2023-09-26
]

---


&lt;style type="text/css"&gt;
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
&lt;/style&gt;



# Agenda

1. Sampling

2. The Central Limit Theorem

3. Estimation

4. An example

---

# Our journey thus far

- Overarching goal: find the **best possible way** to make inferences about populations from samples

--

- Defined social phenomena as **experiments** that yield observations
  
  - Outcomes defined as **events**
    
  - Defined **sample space** as the set of all possible events
    
  - Used **set theory** to guide how we assign probabilities to events
    
--

- Then defined a **random variable** as a function mapping sample space to real numbers
  
  - Built on set theory to describe the **probability distribution** of an RV
    
  - And the probability distribution of a **function** of RVs
    
---

# "Random" variables

- All observed social phenomena are **realizations of random variables**

- Put differently, political scientists study **random events**
  
- We mean "random" differently from the layperson

  - Layperson: "Random" `\(\Rightarrow\)` something that cannot be anticipated
  
  - Us: an event that is **probabilistic** instead of deterministic

- In sum, **random variables** means we expect that the values we observe to be draws from an associated probability distribution
  
---

# Expectations

- Powerful result: if the probability distribution is an accurate representation of the population frequency distribution, then the expected value of an RV is the population mean `\(\mu\)`

Discrete case:
$$
E(Y) \equiv \sum_y yp(y)
$$

Continuous case:
$$
E(Y) \equiv \int_y yf(y)dy
$$

---

# Putting this to work

- Fundamental challenge: **inference**

- What can we say about the **data we don't have**?

- Typically want to say something that **summarizes** the population

  - Central tendency is a very common target!
  
- These "things" we want to say are **parameters**

  - And we "estimate" them with **estimators**

- Definition: **Estimator**

  - A *rule* (often a formula) that tells us how to calculate an **estimate** from a sample
  
- We can come up with many of these, but how do we know if they're any good?

---

# Estimates and Estimators

- What do we mean by "good"?

- Example: the observed sample mean

  - Draw random sample of `\(n\)` observations from a random variable `\(Y\)`
  
$$
\bar{Y} \equiv \frac{y_1 + y_2 + \dots + y_n}{n} = \frac{1}{n}\sum_i y_i
$$

- Is this "good"?

  - Be precise! Is this a "good" estimate of the population parameter `\(\mu\)`?
  
- It feels good...but why?

---

# Simple Example

- Want to know the mean income of the American population

  - `\(\mu\)`: Average income of **all** Americans
  
- But we can't ask everybody (takes too long, too expensive), so we run an **experiment** where we sample Americans **at random** and ask their income

- The response for the first person I ask is `\(y_1\)`
  
  - **NOTE:** `\(y_1\)` is one of literally millions of responses I might have recorded

  - Thus it is **probabilistic**
  
  - Thus we can think of it as a realization of the random variable `\(Y_1\)`
  
- Denote response of second person I ask as `\(y_2\)`

  - AGAIN... `\(y_2\)` is probabilistic and can be thought of as the realization of the random variable `\(Y_2\)`
  
---

# Simple Example Cont'd

- Thus let observed sample of `\(n\)` observations be realizations of `\(n\)` random variables: `\(Y_1, Y_2, \dots, Y_n\)`

- So what is `\(\bar{Y} = \frac{1}{n}\sum_i Y_i\)`?

  - One realization of many possible `\(\bar{Y}\)` values
  
  - `\(\bar{Y}\)` is a **function** of random variables, and therefore **itself** a random variable (recall definition of RV)
  
  - In other words, our observed sample produces `\(\bar{y}\)`, a realization of the random variable `\(\bar{Y}\)`
  
- Since `\(\bar{Y}\)` is a random variable, it has a theoretical probability distribution

  - What does the probability distribution look like?
  
---

# Magic time

- Thus far, we have being pretty **sketchy** about our distributions

  - Talked about *some* in concrete terms (Bernoulli, Binomial, Poisson, Uniform, Normal)
  
  - But mostly been **very** agnostic with our notation: `\(f(y)\)`; `\(F(y)\)` could be (almost) anything
  
- But, thanks to a carefully defined experiment, we be **concrete** about the probability distribution of `\(\bar{Y}\)`

- Specifically, we are working with a **random sample**

  - Choose a set of `\(n\)` observations from a population of size `\(N\)`, producing `\(N \choose n\)` possible samples
  
  - And each of these samples is **equiprobable**
  
- A random sample allows us to assume that the random variables `\(Y_1, Y_2, \dots, Y_n\)` are "i.i.d."

  - **I**ndependent and **I**dentically **D**istributed

---

# IID

- **Independent**: `\(F(y_1,y_2,\dots,y_n) = F_1(y_1)*F_2(y_2)*\dots*F_n(y_n)\)`

- **Identically Distributed**: `\(F_1(y_1) = F_2(y_2) = \dots = F_n(y_n) = F(y)\)`

---

# How good is `\(\bar{Y}\)`?

- We will refer to `\(\bar{Y} = \frac{1}{n}\sum_i Y_i\)` as a **sample statistic**

  - A function of the random variables `\(Y_1,Y_2,\dots,Y_n\)` and "known constants" (in this case, `\(\frac{1}{n}\)`)
  
- We can prove that `\(E(\bar{Y}) = \mu\)` thanks to the **identicality assumption**

  - So we can say `\(\bar{Y}\)` is "good" on average because it will be `\(\mu\)` on average
  
- But how far off might a given sample's `\(\bar{Y}\)` be?

  - This is just the standard deviation of `\(\bar{Y}\)`, or `\(\sigma_{\bar{Y}}\)`
  
  - `\(\sigma_{\bar{Y}} = \sqrt{VAR(\bar{Y})} = \frac{\sigma}{\sqrt{n}}\)` (we can prove with **identicality and independence**)
  
---

# How good is `\(\bar{Y}\)`?

- Remember that `\(\bar{Y}\)` is a random variable and thus it has a probability distribution?

- In general, any **sample statistic** is a random variable and has a probability distribution

- We call these probability distributions **sampling distributions**

  - Literally just the probability distribution for a sample statistic
  
  - They are **theoretical models** for the possible values of the sample statistic we would expect to see through repeated random sampling
  
- We might have one sampling distribution for `\(\bar{Y}\)` and another for `\(\bar{Y'}\)`

  - The "better" sampling distribution is the one whose estimates are closer to the true parameter of interest `\(\mu\)`
  
  - I.e., the one whose variance is **smaller**

---

# How good is `\(\bar{Y}\)`?


&lt;img src="Lecture_7_slides_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---

# Shapes

- But the previous was just an example, wasn't it? There's no way the **sampling distribution** would look like that

  - After all, other random variables can have *any* shape
  
&lt;img src="Lecture_7_slides_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem

- We can rely on a **powerful** result of the math thus far:

- If `\(Y_1, Y_2, \dots, Y_n\)` are i.i.d., then `\(\bar{Y}\)`'s sampling distribution is approximately normal

- See some examples in the handout!

- Formally, let `\(Y_1, Y_2, \dots, Y_n\)` be i.i.d. random variables with:

  - `\(E(Y_i) = \mu\)`
  
  - `\(VAR(Y_i) = \sigma^2\)`
  
- Define `\(U_n \equiv \frac{\bar{Y} - \mu}{\sigma / \sqrt{n}}\)` as the standardized `\(\bar{Y}\)`, and denote `\(F_{U_n}(u)\)` as the CDF of this standardized random variable

- We know that `\(\lim_{n \rightarrow \infty} F_{U_n}(u) \int_{-\infty}^u \frac{1}{\sqrt{2\pi}}e^{-t^2/2} dt\;\; \forall\; u\)`

  - You don't need to know this proof, but see Section 7.4 in WMS if interested
  
---

# Central Limit Theorem

- In plain language: We know the (asymptotic) sampling distribution of `\(\bar{Y}\)` **without requiring any assumptions about the probability distribution of `\(Y\)`**

- We can now actually **calculate** probabilities!

- This is inference!

- This is magic!

- THIS IS SPARTA!

---

# Estimation

- With the CLT in hand, let's return to **estimators**

  - Remember the definition?
  
  - A rule (often a formula) that tells us how to calculate an estimate of a population parameter
  
- Two types:

  1. **Point Estimates**: a single value (i.e., a "point") is given as the estimate of the parameter of interest
  
  2. **Interval Estimates**: two values are used to construct an range (i.e., an "interval") in which the parameter of interest exists

---

# Estimation

- What is `\(\bar{Y} = \frac{1}{n}\sum_i Y_i\)`?

--

  - A point estimate
  
- But there are many other candidates

- Consider `\(\bar{Y}_B = \frac{1}{n} \sum_i(Y_i + 1)\)`

- Is this "good"? No...why not?

- It is "biased"

---

# Aside on notation

- We have been interested in `\(\mu\)` which is a population parameter

- But there are other quantities of the population that we might be interested in

  - Central tendency parameters: median, mode
  
  - Dispersion parameters: range, variance
  
  - (Preview) Relationship parameters: coefficients
  
- Generically, denote a population parameter with `\(\theta\)` and the proposed estimator for this parameter as `\(\hat{\theta}\)`

---

# Bias

- Math of expectations can help us formalize bias

- Define "bias" as an estimator that is equal to the parameter it claims to estimate **in expectation**

  - `\(\hat{\theta}\)` is unbiased for `\(\theta\)` if `\(E(\hat{\theta}) = \theta\)`
  
    - (i.e., `\(E(\bar{Y}) = \mu\)`)
    
  - If `\(E(\hat{\theta}) \neq \theta\)`, then `\(\hat{\theta}\)` is **biased**
  
  - Denote bias as `\(B(\hat{\theta}) = E(\hat{\theta}) - \theta\)`
  
- We can prove an estimator is unbiased using expectations!

---

# Bias

- Does `\(E(\hat{Y}_B) = \mu\)`?

$$
`\begin{aligned}
E(\hat{Y}_B) &amp;= E\bigg[\frac{1}{n}\sum_i^n(Y_i + 1)\bigg]\\
&amp;= \frac{1}{n}\bigg[ \sum_i^n E(Y_i + 1)\bigg]\\
&amp;= \frac{1}{n}\bigg[\bigg(\sum_i^n E(Y_i)\bigg) + \bigg(\sum_i^nE(1)\bigg)\bigg]\\
&amp;= \frac{1}{n}\bigg[\sum_i^n \mu + \sum_i^n 1\bigg]\\
&amp;= \frac{1}{n}(n\mu + n)\\
&amp;= \mu + 1\\
&amp;\neq \mu
\end{aligned}`
$$

---

# Variance

- Recall from earlier when we talked about how close a random sample's `\(\bar{Y}\)` would be to `\(\mu\)`

- This is equivalent to saying we want to minimize the variance of the sampling distribution

- Recall the definition of variance of a random variable

$$
VAR(\hat{\theta}) = E[(\hat{\theta} - E(\hat{\theta}))^2]
$$

- We want to make this as small as possible

---

# "Good" is bias and variance

- **Bias-variance tradeoff**: we often will find ourselves caught between wanting to reduce the bias of an estimator and reducing its variance

- Evaluate this tradeoff using the **mean squared error (MSE)**

$$
MSE(\hat{\theta}) = E[(\hat{\theta} - \theta)^2]
$$

- MSE can be rewritten in terms of both bias and variance

$$
MSE(\hat{\theta}) = VAR(\hat{\theta}) + B(\hat{\theta})^2
$$

- (Ideas on why this includes the square of the estimator's bias?)

---

# Example

- Consider a new parameter of interest, defined as `\(\theta = \mu_1 - \mu_2\)`

  - We are interested in **the difference in means of two different populations**
  
  - Note that we are using `\(Y_1\)` and `\(Y_2\)` to represent random variables from **different populations** here (don't get confused from the notation above)
  
- Is `\(\hat{\theta} = \bar{Y}_1 - \bar{Y}_2\)` unbiased?

  - Easy proof!

---

# Example

- What is `\(\hat{\theta}\)`'s variance?

$$
`\begin{aligned}
VAR(\bar{Y}_1 - \bar{Y}_2) &amp;= VAR(\bar{Y}_1) + VAR(\bar{Y}_2) + 2COV(\bar{Y}_1,\bar{Y}_2)\\
&amp;= VAR(\bar{Y}_1) + VAR(\bar{Y}_2) + 2*0 \;\; \text{(bc} \; \bar{Y}_1,\bar{Y}_2\;\text{are indep)} \\
&amp;= \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}
\end{aligned}`
$$

- We denote the standard error of the estimator `\(\hat{\theta}\)` with `\(\sigma_{\hat{\theta}}\)`, which is just the square root of the variance

  - Thus `\(\sigma_{\bar{Y}_1 - \bar{Y}_2} = \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_{2}^2}{n_2}}\)`
  
---

# Final CLT Variant

- Turns out (beyond the scope of this class) that a variant of the CLT tells us

$$
\bar{Y}_1 - \bar{Y}_2 \sim \mathcal{N}\bigg(\mu_1 - \mu_2, \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}\bigg)\;\; \text{as}\;\; n_1,n_2 \rightarrow \infty
$$

- (Notation reminder! 

  - `\(Y \sim \mathcal{N}(\mu,\sigma^2)\)` is how we write "is distributed normal with mean `\(\mu\)` and standard deviation `\(\sigma^2\)`)


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
