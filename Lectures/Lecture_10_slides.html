<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture 10</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Bisbee" />
    <script src="libs/header-attrs-2.18/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/lexis.css" type="text/css" />
    <link rel="stylesheet" href="css/lexis-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Lecture 10
]
.subtitle[
## Quantitative Political Science
]
.author[
### Prof. Bisbee
]
.institute[
### Vanderbilt University
]
.date[
### Lecture Date: 2023/10/03
Slides Updated: 2023-12-23
]

---


&lt;style type="text/css"&gt;
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
&lt;/style&gt;



# Agenda

1. Finishing up last lecture's example

2. Hypothesis Testing

3. Relation to CIs

4. Two- versus one-tailed tests


---

# Example Time!

- Poll of 1,203 adults between Sep. 15 and 20, 2023 asking about a hypothetical vote choice if the election were held tomorrow, found that 52.5% of respondents indicated they would support Trump, and 47.5% indicated they would support Biden. This marks a reduction in Trump support from a previous tracking poll fielded a week earlier of 1,203 adults who indicated 55.6% support for Trump and 44.4% support for Biden. 

- How confident are we that the change in Trump's support over this period is not due to sampling error?

- Parameter we seek is `\(p_1 - p_2\)` where `\(p_1\)` is Trump's **true** support in the first poll and `\(p_2\)` is his **true** support in the second poll. Consider the polls as binomial experiments in which `\(Y_1\)` is the number of "successes" (here, the # favoring Trump) in the first poll and `\(Y_2\)` is the number of "successes" in the second poll.

- Intuitive estimator: `\(\hat{p}_1 - \hat{p}_2\)`. Is this unbiased?

- Calculate estimator's standard errors: `\(\sqrt{VAR(\hat{p}_1 - \hat{p}_2)} = \sqrt{VAR(\hat{p}_1) + VAR(\hat{p}_2)} = \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}\)`

---

# Example Time!

- Continuing from the previous example, what is the 95% confidence interval for this estimator?

- Does this interval include zero? How can we interpret that?

- What about the 90% confidence interval? Does it still include zero?

- At what level of confidence would we conclude Trump's support changed between the two surveys?

--

- **Think**: want to find `\(\alpha\)` (call it `\(\alpha^*\)`) s.t. the *lower bound of the CI is greater than zero*

$$
`\begin{aligned}
\hat{p}_1 - \hat{p}_2 - z_{\alpha^*/2}\bigg(\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}\bigg) &amp;&gt; 0\\
-z_{\alpha^*/2}\bigg(\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}\bigg) &amp;&gt; -(\hat{p}_1 - \hat{p}_2)\\
z_{\alpha^*/2} &amp;&lt; \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}
\end{aligned}`
$$

---

# Hypothesis Testing

- **Hypothesis Test** consists of four elements:

  1. **Null** hypothesis about a parameter: `\(H_0\)`
  
  2. **Alternative** hypothesis about the parameter: `\(H_A\)`
  
  3. **Test statistic** derived from estimator of the parameter
  
  4. **Rejection region**: range of values of test statistic for which `\(H_0\)` should be *rejected* in favor of `\(H_A\)`
  
- Choosing the RR trades off two kinds of errors:

  - **Type I error**: reject `\(H_0\)` when it is actually true
  
  - **Type II error**: accept `\(H_0\)` when `\(H_A\)` is actually true

---

# Type I Error

- **Type I error**: reject `\(H_0\)` when it is actually true

  - What does this look like?
  
&lt;img src="Lecture_10_slides_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---

# Type I error

- We will (purely by chance):

  - Observe an estimated `\(\hat{\theta}\)` in the *RR* `\(100*\alpha\)`% of the time
  
  - Thus falsely reject the null even though it's true
  
- This is Type I error!

---

# Type II error

&lt;img src="Lecture_10_slides_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

# Type II error

- Suppose that the alternative hypothesis is true

- But we always conduct our hypothesis test **under the assumption that the null is true**

- If the sampling distribution of our estimator `\(\hat{\theta} \sim \mathcal{N}(\theta_A,\sigma_{\hat{\theta}})\)`, we will mistakenly accept the null `\(100*\beta\)`% of the time

- Define **power** as `\(1 - \beta\)`

$$
`\begin{aligned}
\text{Power} &amp;= 1 - \beta \\
&amp;= 1 - Pr(\text{reject }H_0 | H_A\text{ true})\\
&amp;= 1 - Pr(\hat{\theta} &lt; \theta_0 + z_{\alpha/2}\sigma_{\hat{\theta}} | \theta = \theta_A)
\end{aligned}`
$$

---

# Type I and II error

- Thus `\(P(\text{Type I}) = \alpha\)` and `\(P(\text{Type II}) = \beta\)`

- Ideally, we want the hypothesis test's level of significance to be **low** and its power to be **high**

- Why is this a trade-off?

- Re-evaluate the example:

  - `\(H_0: p_1 - p_2 = 0\)`
  
  - `\(H_A: p_1 - p_2 \neq 0\)`
  
- Test statistic is `\(\hat{p}_1 - \hat{p}_2\)`

- Rejection region is all values of statistic for which we reject `\(H_0\)` for chosen `\(\alpha\)`

  - I.e., values of `\(\hat{p}_1 - \hat{p}_2\)` where the constructed CI **does not include zero**
  
---

# Type I and II errror

- Recall our CI: `\((\hat{p}_1 - \hat{p}_2) \pm z_{\alpha/2} \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}\)`

- We could have rejected `\(H_0\)` if `\((\hat{p}_1 - \hat{p}_2) - z_{\alpha/2} \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}} &gt; 0\)` and concluded Trump's popularity did fall

- Rewriting:

$$
`\begin{aligned}
(\hat{p}_1 - \hat{p}_2) &amp;&gt; z_{\alpha/2} \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}\\
\frac{(\hat{p}_1 - \hat{p}_2)}{z_{\alpha/2} \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}} &amp; &gt; z_{\alpha/2}
\end{aligned}`
$$

---

# Sample Size

- What sample size would have been needed for our difference in sample populations to be statistically significant from zero with 95% confidence? (Assume `\(n_1 = n_2 = n\)`)

- Plug in the numbers!

- Power calculation is a crucial tool for determining how big your sample must be to avoid committing Type II error

- (We will come back to this soon)

---

# Relation to CIs

- Walk through a question

  - Conventional wisdom says that `\(\theta = \theta_0\)`, but I theorize that `\(\theta \neq \theta_0\)`
  
  - I obtain a point estimate `\(\hat{\theta} \neq \theta_0\)`
  
  - How sure am I that `\(\theta \neq \theta_0\)`?
  
- This is the core language of **hypothesis tests**

- Often `\(\theta_0 = 0\)`, but it could be any value

- Regardless, we can fully define the distribution of our estimator if `\(\theta_0\)` is true

- We know that CLT tells us that the standardized version of **any** estimator is `\(\frac{\hat{\theta} - \theta_0}{\sigma_{\hat{\theta}}} \sim \mathcal{N}(0,1)\)`

---

# Hypothesis Testing

- Remember...4 components!

  1. Null hypothesis `\(H_0\)`
  
  2. Alternative hypothesis `\(H_A\)`
  
  3. Test statistic `\(\hat{\theta}\)`
  
  4. Rejection region
  
- Start by choosing `\(\alpha\)` which is now defined as **the probability of Type I error**

- Then identify the range of values of `\(\hat{\theta}\)` we will observe `\(\alpha\)` percent of the time in repeated sampling, which is our **rejection region**

- If we observe `\(\hat{\theta}\)` in this region, we reject `\(H_0: \theta = \theta_0\)` in favor of `\(H_A: \theta \neq \theta_0\)`

- In practice, we reject `\(H_0\)` if `\(\hat{\theta} &lt; \theta_0 - z_{\alpha/2}\sigma_{\hat{\theta}}\)` or if `\(\hat{\theta} &gt; \theta_0 + z_{\alpha/2}\sigma_{\hat{\theta}}\)`

---

# One-Tailed Hypothesis Test

- What if we have a stronger alternative hypothesis?

  - Our alternative is **signed**
  
  - Instead of `\(H_A: \theta \neq \theta_0\)`, I have theoretical reason to believe `\(H_A: \theta &gt; \theta_0\)`
  
- Again, pick `\(\alpha\)`

- Then look at the standard Normal and identify range of values for `\(\hat{\theta}\)` greater than `\(\theta_0\)` that we will observe `\(\alpha\)`% of the time in repeated sampling

- Beware of cooking the books! Say you have some `\(\hat{\theta} &gt; \theta_0\)`, and you make an *ex post* hypothesis that `\(H_A: \hat{\theta} \geq \theta_0\)`. This is not based on theory, and looks very suspicious!




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
